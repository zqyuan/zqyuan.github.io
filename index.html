<!DOCTYPE html>
<html style="" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage no-websqldatabase indexeddb hashchange history draganddrop websockets rgba 
hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent 
video audio localstorage sessionstorage webworkers no-applicationcache svg inlinesvg smil svgclippaths"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Zhaoquan Yuan</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="">
	<meta name="keywords" content="">
	<meta name="author" content="">



  
    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="./zqyuan_files/js"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-155179995-1');
    </script>

     


	

	<!-- Animate.css -->
    <link rel="stylesheet" href="./animate.css">	
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="./icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="./bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="./flexslider.css">
	<!-- Flaticons  -->
	<link rel="stylesheet" href="./flaticon.css">
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="./owl.carousel.min.css">
	<link rel="stylesheet" href="./owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="./style.css">

	<!-- Modernizr JS -->
	<script src="./modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->
  
	</head>



<!---------------body---------->
<body>
<div id="colorlib-page">
<div class="container-wrap">
<a href="https://zqyuan.github.io" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><i></i></a>





<!---------------左侧---------->
<aside id="colorlib-aside" role="complementary" class="border js-fullheight" style="height: 1529px;">

<!---------------照片---------->
<div class="text-center">
<p><img alt="" src="jorain0.jpeg" style="WIDTH: 112px; HEIGHT: 156px" /></p>
<h1 id="colorlib-logo"><a href="index.html"> <a><p style="FONT-FAMILY:Arial; font-size:22px">Zhaoquan Yuan</p></a></h1>

<p style="FONT-FAMILY:Arial; font-size:14px"> 
Associate Professor <br>
School of Computing and Artificial Intelligence<br>
Southwest Jiaotong University
<br>
<br>
</p>

</div>


<!--
<hr/>
<div class="text-center">
<p style="FONT-FAMILY:Arial; font-size:13px">ADRESS: No. 999, Xi'an Road, Pidu District, Chengdu, China PR. POSTCODE: 611756. </p>
<p style="FONT-FAMILY:Arial; font-size:13px"> 
Eail:&nbsp;zqyuan0@gmail.com
</p>
</div>
-->




<hr/>
<!---------------网站导航---------->
<nav id="colorlib-main-menu" role="navigation" class="navbar">
<div id="navbar" class="collapse">

<ul>
<li class=""><a href="index.html">ABOUT</a></li>
<li class=""><a href="./#招生"> 招生信息 </a></li>
<li class=""><a href="./#NEWS"> NEWS </a></li>
<li class=""><a href="./#REWARDS"> REWARDS </a></li>
<li class=""><a href="./#PUBLICATIONS"> PUBLICATIONS </a></li>
<li class=""><a href="./#TEACHING"> TEACHING </a></li>
<li class=""><a href="./#FUNDS"> FUNDS </a></li>
<li class=""><a href="./#SERVICES"> SERVICES </a></li>
<li class=""><a href="./#STUDENTS"> STUDENTS </a></li>

<!-- <li class=""><a href="https://zqyuan.github.io/#RESOURCE"> RESOURCE </a></li> -->

</ul>
</div>
</nav>


</aside>




<!--------------- 个人简介---------->
<div id="colorlib-main">
<section data-section="ABOUT" id="ABOUT">
<div class="colorlib-narrow-content" align="left">
<br>   
<br>

<h1 style="FONT-FAMILY:Arial; font-size:25px;">ABOUT ME</h1>
<p style="FONT-FAMILY:Arial; font-size:14px">
I currently serve as an Associate Professor in the School of Computing and Artificial Intelligence at Southwest Jiaotong University (SWJTU). 
I obtained my bachelor's degree from the School of Computer Science and Technology at the University of Science and Technology of China (USTC). 
Subsequently, I earned my Ph.D. in Pattern Recognition and Intelligent Systems from the Multimedia Computing Group (MMC) at the Institute of Automation, 
Chinese Academy of Sciences, under the supervision of Professor <a href="http://nlpr-web.ia.ac.cn/mmc/homepage/csxu.html"  target="_blank">Prof. Changsheng Xu</a>
 and co-supervision of Professor <a href="https://faculty.bjtu.edu.cn/9129/"  target="_blank">Prof. Jitao Sang</a>. 
My academic experience encompasses research visits at the China-Singapore Institute of Digital Media (CSIDM) and the Department of Computing at The Hong Kong Polytechnic University.


</p>



<p style="FONT-FAMILY:Arial; font-size:14px">
My research interests lie in computer vision, generative AI, and deep learning, with particular emphasis on two primary areas: <br>
(1) <strong>3D Computer Vision</strong>: 3D reconstruction, 3D content generation, Multimodal learning, etc. <br>
(2) <strong>Generalizable Learning</strong>:  Continual learning, Compositional learning, etc. 

</p>  

<p style="FONT-FAMILY:Arial; font-size:13px">
Adress: No. 999, Xi'an Road, Pidu District, Chengdu, China PR.   &nbsp Postcode: 611756.    &nbsp Eail: zqyuan0@gmail.com
</p>


	
<br>

</div>
</section>




<!--------------- 招生---------->
<section data-section="招生" id="招生">
<div class="colorlib-narrow-content" align="left">
<hr/>
<h1 style="FONT-FAMILY:Arial; font-size:25px;">招生信息</h1>
<p style="FONT-FAMILY:Arial; font-size:14px">


袁召全，现任西南交通大学计算机与人工智能学院副教授，硕士生导师。
本科毕业于中国科学技术大学计算机科学与技术学院，博士毕业于中国科学院大学（中国科学院自动化研究所，导师：徐常胜研究员）。
曾先后在中国-新加坡数字媒体研究院、香港理工大学计算机科学系交流访问。
曾获国际学术会议ACM MM Asia 2024最佳论文奖、MMM 2021最佳论文奖、2024年度中国发明协会发明创业奖创新奖、2024年度广西应急管理协会安全科技进步奖。
近年来在CVPR、ACM MM、IJCAI、IEEE TMM等国际学术会议及期刊发表论文近30篇。
任多届CVPR、ACM MM、ACL、AAAI、IJCAI、EMNLP、ICMR、ICME等国际会议程序委员会委员，及多个IEEE Trans、ACM Trans期刊审稿人。
先后主持国家自然科学基金青年项目、四川省自然科学基金项目、四川省科技计划基础研究项目、中国博士后基金项目等多项。

主要研究方向包括计算机视觉、生成式AI、深度学习、多模态学习等，目前重点关注：<br>
(1) <strong>三维视觉</strong>：3D重建，3D内容生成，多模态学习等；<br> 
(2) <strong>可泛化的深度学习</strong>：持续学习，组合学习等。  

</p>



<p>
<font color="#C70039">
<p style="FONT-FAMILY:Arial; font-size:14px">
欢迎具备以下条件的同学加入科研团队：<br>
(1) 良好的自我驱动力，对学术探索/工程技术有强烈的兴趣与热情；<br>
(2) 数学与编程基础扎实，对计算机视觉、深度学习、3D视觉、多模态等AI前沿技术感兴趣；<br>
(3) 责任心强，有团队合作精神，诚信可靠。<br>
有意向的同学请邮件联系：zqyuan0@gmail.com

</font>
</p>
</p>
<br>


</div>
</section>




<!---------------新闻---------->
<section data-section="NEWS" id="NEWS">
<div class="colorlib-narrow-content" align="left">

<hr/>	
<h1 style="FONT-FAMILY:Arial; font-size:25px;">NEWS</h1>	

<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<!--
<li> 
<font size=“14px” color="#2D98F0"> [<I>March 14, 2025</I>] </italic> </font> 
Two papers have been accepted for presentation at the ICME 2025.
</li>


<li> 
<font size=“14px” color="#2D98F0"> [<I>Feb 21, 2025</I>] </italic> </font> 
Our research paper titled "Disentanglement-based Equivariant Learning for Compositional VQA" has been accepted for publication in IEEE TMM 2025.
</li>
-->


<li> 
<font size=“14px” color="#2D98F0"> [<I>Dec 5, 2024</I>] </italic> </font> 
Our paper "TMM-CLIP: Task-guided Multi-Modal Alignment for Rehearsal-Free Class Incremental Learning" has received the Best Paper Award at the ACM MM Asia 2024.
</li>



<li> 
<font size="" color="#2D98F0"> [<I>March 27, 2024</I>] </italic> </font> Paper 
"PostureHMR: Posture Transformation for 3D Human Mesh Recovery" is accepted by CVPR 2024 (CCF-A). 
</li>


<li> 
<font size="" color="#2D98F0"> [<I>July 27, 2023</I>] </italic> </font> Paper 
"Human-Object-Object Interaction: Towards Human-Centric Complex Interaction Detection" is accepted by ACM MM 2023 (CCF-A). 
</li>


<li> 
<font size="“14px”" color="#2D98F0"> [<I>Dec 27, 2022</I>] </italic> </font> 邵焕同学获西南交通大学2022年度优秀硕士论文奖！ 
</li>


<li> 
<font size="" color="#2D98F0"> [<I>June 30, 2022</I>] </italic> </font> Paper 
"Domain-Specific Conditional Jigsaw Adaptation for Enhancing transferability and Discriminability" is accepted by ACM MM 2022 (CCF-A). 
</li>


<li> 
<font size="" color="#2D98F0"> [<I>Junly 4, 2021</I>] </italic> </font> Paper 
"Hierarchical Multi-Task Learning for Diagram Question Answering with Multi-Modal Transformer" is accepted by ACM MM 2021 (CCF-A, Oral). 
</li>


<li> 
<font size="" color="#2D98F0"> [<I>June 24, 2021</I>] </italic> </font> Paper 
"Contrastive learning in frequency domain for Non-I.I.D. image classification" is awarded as best paper at MMM 2021.
</li>


<li> 
<font size="" color="#2D98F0"> [<I>June 1, 2020</I>] </italic> </font> Paper
"Adversarial Multimodal Network for Movie Question Answering" is accepted by IEEE Trans. on Multimedia.
</li>


</ul>

<br>
<br>
</div>
</section>

	

<!--------------科研奖励---------->
<section data-section="REWARDS" id="REWARDS">
<div class="colorlib-narrow-content" align="left">
<hr/>	
<h1 style="FONT-FAMILY:Arial; font-size:25px;">REWARDS</h1>	
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li>
国际学术会议 Multimedia Modeling 2021最佳论文奖，捷克布拉格，2021-06-24
</li>

<li>
国际学术会议 ACM Multimedia Asia 2024最佳论文奖，新西兰奥克兰，2024-12-5
</li>


<li>
2024年度中国发明协会发明创业奖创新奖，二等奖，第二完成人，2024-07
</li>

</ul>

<br>
</div>
</section>





<!---------------论文列表---------->
<section data-section="PUBLICATIONS" id="PUBLICATIONS"> 
<div class="colorlib-narrow-content" align="left">	
<hr/>
<h1 style="FONT-FAMILY:Arial; font-size:25px;">SELECTED PUBLICATIONS</h1>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >

<!---->


<!--
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Fangying Xiong, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Wu, and Changsheng Xu. <br> 
Class-Specific Knowledge-Guided Multimodal Prompt Tuning for Few-Shot Class-Incremental Learning.<br> 
<I>IEEE Transactions on Circuits and Systems for Video Technology, 2025.</I> (TCSVT, 中科院1区)
</li>
-->









<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Xuan Yao, Xiao Peng, Junyu Gao, <strong>Zhaoquan Yuan</strong>, Xiao Wu, and Changsheng Xu.<br> 
Active Cross-modal Domain Adaptation.<br> 
<I>IEEE Transactions on Multimedia, 2025.</I> (TMM, 中科院1区)
</li>




<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Chengbin Zhao, Yuting Tang, Lishu Guo, Xiao Wu, and Changsheng Xu. <br> 
Contrastive Invariant Risk Minimization for Grounded Situation Recognition.<br> 
<I>IEEE International Conference on Multimedia & Expo, June 30-July 4, 2025. Nantes, France </I> (ICME)
</li>






<li>
<p style="text-align:justify"; text-justify:inter-ideograph;> 
Zhou Du, <strong>Zhaoquan Yuan</strong><sup>*</sup>, Xiao Wu, and Changsheng Xu.<br> 
Disentanglement-based Equivariant Learning for Compositional VQA.<br>
<I>IEEE Transactions on Multimedia, 2025.</I> (TMM, 中科院1区)
</li>












<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Yuankang Pan, <strong>Zhaoquan Yuan</strong>, Xiao Wu, Zechao Li, and Changsheng Xu.<br>
TMM-CLIP: Task-guided Multi-Modal Alignment for Rehearsal-Free Class Incremental Learning.<br>
<I>Proceedings of ACM Multimedia Asia, pp. 1-7.  December 03–06, 2024, Auckland, New Zealand.  <br/>
https://doi.org/10.1145/3696409.3700182. </I>
(MM Asia, <font size="" color="#2D98F0"> <strong>最佳论文奖</strong> </italic> </font>)
</li>





<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Chongyang Xiang, Xiao Wu, Jun-Yan He,  <strong>Zhaoquan Yuan</strong>, and Tingquan He.<br>
Person in Uniforms Re-Identification.<br>
<I>ACM Transactions on Multimedia Computing Communications and Applications, Volume 21, Issue 2, pp. 1-23, 2024. <br/>
https://doi.org/10.1145/3703839.  </I>
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Yu-Pei Song, Yuantong Liu, Xiao Wu, Qi He,  <strong>Zhaoquan Yuan</strong>, and Ao Luo.<br>
MagicCartoon: 3D Pose and Shape Estimation for Bipedal Cartoon Characters.<br>
<I>Proceedings of the 32nd ACM International Conference on Multimedia, pp. 8219-8227. Oct 28–Nov 1, 2024, Melbourne, Australia. </I> (ACM MM, CCF-A)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Yu-Pei Song, Xiao Wu, <strong>Zhaoquan Yuan</strong>, Jian-Jun Qiao, and Qiang Peng.<br>
PostureHMR: Posture Transformation for 3D Human Mesh Recovery.<br>
<I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9732-9741. June 19-21, 2024. Seattle WA, USA.</I> (CVPR, CCF-A)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Ming-Xuan Zhang, Xiao Wu, <strong>Zhaoquan Yuan</strong>, Qi He, and Xiang Huang.<br>
Human-Object-Object Interaction: Towards Human-Centric Complex Interaction Detection.<br>
<I>Proceedings of the 31st ACM International Conference on Multimedia, pp. 2233-2242. Oct 29–Nov 3, 2023. Ottawa, Canada. </I> (ACM MM, CCF-A)
</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Ying Shen, Wei Li, <strong>Zhaoquan Yuan</strong>, and Xiao Wu.<br>
Learning Surface-awareness Network for X-Ray Prohibited Item Detection.<br>
<I>Proceedings of the 5th ACM International Conference on Multimedia in Asia, pp. 1-5. Dec 6-8, 2023. Tainan Taiwan. </I>
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Qi He, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Wu, and Jun-Yan He.<br> 
Domain-Specific Conditional Jigsaw Adaptation for Enhancing Transferability and Discriminability.<br>
<I>Proceedings of the 30th ACM International Conference on Multimedia, pp. 6327-6336. Oct 10-14, 2022. 
Lisbon Portugal. https://doi.org/10.1145/3503161.3547890. </I> (ACM MM, CCF-A)

</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Wei Li, Tianzhao Yang, Xiao Wu, and <strong>Zhaoquan Yuan</strong>.<br> 
Learning Graph-based Residual Aggregation Network for Group Activity Recognition.<br>
<I>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, pp. 1102-1108. July 23-29, 2022.
Messe Wien, Vienna, Austria. </I> (IJCAI, CCF-A)

</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Xiao Peng, Xiao Wu<sup>*</sup>, and Changsheng Xu.<br> 
Hierarchical Multi-Task Learning for Diagram Question Answering with Multi-Modal Transformer.<br>
<I>Proceedings of the 29th ACM International Conference on Multimedia, pp. 1313-1321. Oct 20-24, 2021. Chengdu, China. </I> (ACM MM, CCF-A)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Siyuan Sun, Lixin Duan<sup>*</sup>, Changsheng Li<sup>*</sup>, Xiao Wu, and Changsheng Xu.<br> 
Adversarial Multimodal Network for Movie Story Question Answering.<br> 
<I>IEEE Transactions on Multimedia, vol. 23, pp. 1744-1756, 2021.</I> (TMM, 中科院1区)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Xiao Peng, Xiao Wu<sup>*</sup>, Bingkun Bao, and Changsheng Xu.<br>
Meta-Learning Causal Feature Selection for Stable Prediction.<br> 
<I>2021 IEEE International Conference on Multimedia and Expo (ICME), pp. 1-6. IEEE. July 5-9, 2021. Shenzhen, China. </I> (ICME, CCF-B)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Huan Shao, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Peng, and Xiao Wu.<br> 
Contrastive Learning in Frequency Domain for Non-I.I.D. Image Classification.<br> 
<I>Proceedings of the 27th International Conference on Multimedia Modeling, pp. 111-122. June 22–24, 2021. Prague, Czech Republic. </I> 
(MMM, <font size="" color="#2D98F0"> <strong>最佳论文奖</strong> </italic> </font>)
</li>


  
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Jun-Yan He, Xiao Wu, Zhi-Qi Cheng, <strong>Zhaoquan Yuan</strong>, and Yu-Gang Jiang.<br> 
DB-LSTM: Densely-Connected Bi-directional LSTM for Human Action Recognition.<br> 
 <I>Neurocomputing, 444, pp.319-331, 2021</I> (中科院1区)
</li>
  

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Changsheng Xu<sup>*</sup>, Jitao Sang, Shuicheng Yan, and M. Shamim Hossain.<br> 
Learning Feature Hierarchies: A Layer-Wise Tag-Embedded Approach.<br> 
<I>IEEE Transactions on Multimedia, vol. 17, no. 6, pp. 816-827, 2015.</I> (TMM, 中科院1区)
</li>
  

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Jitao Sang, Changsheng Xu<sup>*</sup>, and Yan Liu.<br> 
A Unified Framework of Latent Feature Learning in Social Media.<br> 
<I>IEEE Transactions on Multimedia, vol. 16, no. 6, pp. 1624-1635, 2014.</I> (TMM, 中科院1区)
</li>


  
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Jitao Sang, Yan Liu, and Changsheng Xu<sup>*</sup>.<br>
Latent Feature Learning in Social Media Network.<br>  
<I>Proceedings of the 21st ACM international conference on Multimedia, pp. 253-262. Oct 21-25, 2013. Barcelona, Spain. </I> (ACM MM, CCF-A)
</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
<strong>Zhaoquan Yuan</strong>, Jitao Sang, and Changsheng Xu<sup>*</sup>.<br> 
Tag-aware Image Classification via Nested Deep Belief Nets.<br> 
<I>2013 IEEE international conference on Multimedia and Expo, pp. 1-6. IEEE. July 15-19, 2013. San Jose, CA, USA. </I> (ICME)
</li>



</ul>

<br> 


</div>
</section>




<!--------------教学---------->
<section data-section="TEACHING" id="TEACHING">
<div class="colorlib-narrow-content" align="left">
<hr/>	
<h1 style="FONT-FAMILY:Arial; font-size:25px;"> TEACHING </h1>

	
<h3 style="FONT-FAMILY:Arial; font-size:18px;">Undergraduate Courses</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li>Digital Image Processing, SCAI004012, 2024 – 2025(1)
</li>

<li>Natural Language Processing, SCAI008012, 2023 – 2024(2)
</li>

<li>Digital Image Processing, SCAI004012, 2023 – 2024(1)
</li>

<li>Digital Image Processing, SCAI004012, 2022 – 2023(1)
</li>

<li>Digital Image Processing, 3143324, 2021 – 2022(1)
</li>

<li>Digital Image Processing, 0371053, 2020 – 2021(2)
</li>

<li>Digital Image Processing, 3143324, 2020 – 2021(1)
</li>

<li>Digital Image Processing, 0371053, 2019 – 2020(2)
</li>

<li>Digital Image Processing, 3143324, 2019 – 2020(1)
</li>

<li>Digital Image Processing, 0371053, 2018 – 2019(2)
</li>


</ul>


<br>
<h3 style="FONT-FAMILY:Arial; font-size:18px;">Graduate Course</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li> Natural Language Processing, 2024 – 2025(2)
</li>

<li> Natural Language Processing, 2023 – 2024(2)
</li>

<li> Natural Language Processing, 2022 – 2023(2)
</li>

<li> Natural Language Processing, 2021 – 2022(2)
</li>


</ul>

<br>
</div>
</section>





<!--------------项目---------->
<section data-section="FUNDS" id="FUNDS">
<div class="colorlib-narrow-content" align="left">	
<hr/>
<h1 style="FONT-FAMILY:Arial; font-size:25px;">GRANT AND FUNDS</h1>	
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >

<li>
Intelligent Parameter Learning and Image Reconstruction in Adaptive Optical Systems, 2024.12 – 2026.11, the Fund of National Laboratory on Adaptive Optics, China, FNLAO-24-ZD-O02
</li>


<li>
Causal Mechanism-based Multimodal Continual Learning, 2024.01 – 2025.12, Natural Science Foundation of Sichuan Province, 2024NSFSC0508
</li>


<li>
Machine Learning and Reasoning in Video Question Answering, 2019.01 – 2021.12, National Natural Science Foundation of China, 61802053
</li>

<li>
Machine Reasoning Research Towards Multimodal Question Answering, 2020.01 – 2022.12, Sichuan Science and Technology Program, 2020YJ0037
</li>

<li>
Key Technologies of Video Question Answering System, China Postdoctoral Science Foundation, 2020M683353
</li>

<li>
Semantic Understanding toward Video Question Answering, 2019.01 – 2020.12, Fundamental Research Funds for the Central Universities, 2682019CX62
</li>

</ul>

<br>
</div>
</section>






<!--------------学术服务---------->
<section data-section="SERVICES" id="SERVICES">
<div class="colorlib-narrow-content" align="left">
<hr/>	
<h1 style="FONT-FAMILY:Arial; font-size:25px;">SERVICES </h1>	

	
<h3 style="FONT-FAMILY:Arial; font-size:18px;">Program Committee Member</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li>ACM International Conference on Multimedia, 2019 – present </li>
<li>International Conference on Computer Vision, 2025 – present </li>
<li>Association for the Advancement of Artificial Intelligence, 2022 – present </li>
<li>International Joint Conference on Artificial Intelligence, 2023 – present </li>
<li>Annual Meeting of the Association for Computational Linguistics, 2023 – present </li>
<li>International Conference on Empirical Methods in Natural Language Processing, 2021 – present </li>
<li>ACM International Conference on Multimedia Retrieval, 2019 – present </li>
<li>IEEE International Conference on Multimedia and Expo, 2019 – present </li>
<li>International Conference on Multimedia Modeling, 2019 – present </li>
<li>ACM International Conference on Multimedia in Asia, 2019 – present </li>

</ul>


<br>
<h3 style="FONT-FAMILY:Arial; font-size:18px;">Journal Reviewer</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >

<li>IEEE Transactions on Multimedia </li>
<li>IEEE Transactions on Circuits and Systems for Video Technology </li>
<li>IEEE Transactions on Neural Networks and Learning Systems </li>
<li>IEEE Transactions on Cybernetics </li>
<li>ACM Transactions on Multimedia Computing Communications and Applications</li>
<li>Pattern Recognition </li>
<li>Multimedia Systems </li>
<li>Multimedia Tools and Applications </li>


</ul>



<br>
</div>
</section>






<!--------------学生名单---------->
<section data-section="STUDENTS" id="STUDENTS">
<div class="colorlib-narrow-content" align="left">
<hr/>	
<h1 style="FONT-FAMILY:Arial; font-size:25px;">STUDENTS</h1>	

	
<h3 style="FONT-FAMILY:Arial; font-size:18px;">PhD Students</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li>Jing Zhou (Co-superviser)
</li>

<li>Yuankang Pan (Co-superviser)
</li>

<li>Fangying Xiong (Co-superviser)
</li>


</ul>


<br>
<h3 style="FONT-FAMILY:Arial; font-size:18px;">Master Students</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >

<li>Yuting Liu, Yuan Lin, Guoshuai Liang, Liaoliao Ren (Co-superviser), Kunlin Liang (Co-superviser)
</li>

<li>Yuke Li, Yuting Tang, Maorui Zhang, Cong Zheng, Xuehui Chen, Yang Liu (Co-superviser), Tao Liu (Co-superviser), Jicheng Liu (Co-superviser)
</li>

<li>Zihao Luan, Jiangbo Chai, Hongxiao Yuan, Ting Pan, Fanpeng Li, Zimeng Wang (Co-superviser), Shengkai Wan (Co-superviser), Xinhan Lian (Co-superviser), Zhou Du (Co-superviser)
</li>

<li>Zining Wang, Wen Xu, Jie Tang, Zijia Liang, Bojie Ma (Co-superviser), Yuan Ma (Co-superviser), Zhun Zhong (Co-superviser)
</li>

</ul>


<br>

<h3 style="FONT-FAMILY:Arial; font-size:18px;">Graduated Students</h3>
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li>Chengbin Zhao, Huancheng Xu, Baili Zhou, Huan Shao (优秀硕士论文奖), Xiao Peng
</li>

</ul>



<br>
</div>
</section>



<!--------------资源链接---------->
<section data-section="RESOURCE" id="RESOURCE">
<div class="colorlib-narrow-content" align="left">	
<hr/>
<h1 style="FONT-FAMILY:Arial; font-size:25px;"> RESOURCE </h1>	
<ul style=" FONT-FAMILY:Arial; padding-left:14px; font-size:14px" >


<li><a href="https://proceedings.neurips.cc/"  target="_blank">NeurIPS Proceedings</a>
</li>


<li><a href="https://openaccess.thecvf.com/menu"  target="_blank">Computer Vision Foundation</a>
</li>


<li><a href="https://ieeexplore.ieee.org/xpl/issues?punumber=34&isnumber=10916529"  target="_blank">Issues in PAMI</a>
</li>

<li><a href="https://link.springer.com/journal/11263/volumes-and-issues"  target="_blank"> Issues in IJCV</a>
</li>







<li><a href="https://proceedings.mlr.press/"  target="_blank">PMLR</a>
</li>

<!--
<li><a href="http://www.zhuanzhi.ai/topic/2001826911580295" target="_blank">专知知识分享平台</a>
</li>
-->

<!--
<li><a href="https://github.com/hitcslj/Awesome-AIGC-3D?tab=readme-ov-file"  target="_blank"> Awesome-AIGC-3D </a>
</li>
-->

<!--
<li><a href="http://out-of-distribution-generalization.com/"  target="_blank">OOD Generalization</a>
</li>
-->


</ul>

<br>
</div>
</section>
<hr/>



<!--------------更新日期---------->
<div class="colorlib-narrow-content" align="left">
<p style="FONT-FAMILY:Arial; font-size:14px">
 Last updated date: March 21, 2025.
</p> 
 
	
<br>
</div>
        
	
<!--------------结束---------->

</body></html>
