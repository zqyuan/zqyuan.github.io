<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=gbk">
<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
<title>Zhaoquan Yuan's Homepage </title>
<style>
body {
font-family: "Times New Roman", "Helvetica Neue", Helvetica, Arial, sans-serif;
color: #444;
font-size: 62.5%;
background: #f4f4f4;
}

a:link,
a:visited {
color: #1279f8;
text-decoration: none;
}

a:hover {
text-decoration: underline;
}

.main {
display: flex;
}

.left {
font-size: 16px;
line-height: 1.3;
background: #fff;
border-radius: 6px;
-webkit-box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
position: fixed;
top: 8px;
left: 8px;
bottom: 8px;
float: left;
width: 285px;
min-width: 285px;
margin:0px;
}

.right {
margin: 0 0 0 10px;
flex-grow: 1;
font-size: 17px;
line-height: 1.8;
background: #fff;
border-radius: 6px;
margin-left: 295px;
padding-top:0px;
-webkit-box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
}

.rightBox {
padding: 5px 100px 20px;
border-top: 1px solid #eee;
position: relative;
}
.rightBox>p{
margin-top: -80px;
padding-top: 80px;
}

.rightBox table {
border-top: 1px solid #e2b0b5;
border-left: 1px solid #e2b0b5;   <!*********************>
}

.rightBox td,
.rightBox th {
border-right: 1px solid #e2b0b5;
border-bottom: 1px solid #e2b0b5;
}

.rightBox th {
padding: 10px;
}

.rightBox td {
font-size: 16px;
line-height: 1.8;
padding: 10px;
}

.right h4 {
font-family: "Roboto Condensed", sans-serif;
margin-bottom: 10px;
position: relative;
color: #000;
font-size: 18px;
line-height: 20px;
}

.text span {
border: orangered 1px solid;
color: #fff;
padding: 0px 8px;
margin-right: 8px;
border-radius: 10px;
color: orangered;
}

.box {
padding: 20px 30px;
border-top: 1px solid #eee;
position: relative;
}

h1 {
margin: 0 0 10px 0;
text-align: center;
font-size: 20px
}

h1 p {
text-align: center;
}

.headerImg {


display: block;
width: 200px;
height: 200px;
margin: 0 auto 5px auto;
border-radius: 10%;
}

h3 {
margin: 0 0 10px 0;
font-size: 18px;
font-weight: 500;
letter-spacing: .02em;
text-transform: uppercase;
color: #999;
}

.wrap {
position: fixed;
top: 8px; right: 8px; left: 303px;
border-bottom: 1px solid #f4f4f4;
background: #fff; z-index: 10;
}
.wrap:before {
display: block;
content: '';
position: fixed;
top: 0px; right: 8px; left: 303px; height: 8px;
background: #f4f4f4;

}

.wrap ul {
padding: 0 30px;
text-align: center;
}

.wrap li {
display: inline-block;
margin: 10px 10px 0 0;
font-size: 18px;
height: 20px;
line-height: 20px;
line-height: 1;
}

.wrap li:hover {}

.wrap li a {
display: inline-block;
color: #444;
}

.wrap li a {
text-decoration: none;
color: #444;
background: #fff;
padding: 6px;
}

.wrap li a:hover {
color: #fff;
background: #3399FF;  <!***************>
padding: 6px;
}
.backtop{
position: fixed;
right: 2rem;
bottom: 2rem;
z-index: 1000;
border: 1px solid red；
}
a>.btnbacktop{
font-size: 2rem;
margin: 1rem 0 0;
padding: 0;
width: 3.33rem;
height: 3.33rem;
line-height: 0;
color: #333;
background-color: #ffffff;
border: 1px solid #e3e8ee;
border-radius: 50%;
box-shadow: 0 0 5px rgba(0,0,0,.05);
}
#hqestop img{opacity:0.6;}

@media screen and (max-width: 1100px) {
.main {
flex-direction: column;

}
.main .wrap {
display: none;
}

.main .left {
width:100%;
left: 0px;
position: relative;
}

.main .right {
width: 100%;
margin: 10px 0 0 0;
box-sizing: border-box;
}
}
</style>
</head>

<!*************************个人信息************************>

<body>
<div class="main">
<div class="left">
<h1>
<p><img alt="" src="profilePhoto.JPG" style="WIDTH: 127px; HEIGHT: 180px" /></p>
<p><b>
Zhaoquan Yuan
</b>
</p>
</h1>


<div class="box">

<p> <i>Associate Professor, Ph.D.<br>
</i></p>

<p>
School of Computing and Artificial Intelligence, Southwest Jiaotong University</p>
<p>
Engineering Research Center of Sustainable Urban Intelligent Transportation, Ministry of Education, China
</p>

</div>


<div class="box">
<h3>contact</h3>
<p> ADRESS:
No. 999, Xi'an Road, Pidu District, Chengdu, China PR. 
</p>

<p> POSTCODE: 611756.
</p>

EMAIL:&nbsp; zqyuan0@gmail.com


<!----------->

</div>
<p></p>
</div>
</div>

<!*************************目录************************>

<div class="right">
<div class="wrap">
<ul>
<li><a href="index.html">HOMEPAGE</a></li> &nbsp; &nbsp; 
<li><a href="./#PUBLICATIONS">PUBLICATION</a></li> &nbsp; &nbsp; 
<li><a href="./#RESOURCE">RESOURCE</a></li> &nbsp; &nbsp; 
<li><a href="./#recruit">招生信息</a></li>


</ul>

</div>


<!*************************BRIEF BIOGRAPHY************************>
<div class="rightBox text">
<p id="BIOGRAPHY">
<br>
<br>
<br>
<font size="5"><b>BRIEF BIOGRAPHY</b></font>
</p>

<p style="text-align:justify"; text-justify:inter-ideograph;>

Zhaoquan Yuan is now an Associate Professor at the <a href="https://scai.swjtu.edu.cn/index.htm"  target="_blank">School of Computing and Artificial Intelligence</a>, Southwest Jiaotong University (SWJTU). 
I graduated with my bachelor's degree from the School of Computer Science and Technology, University of Science and Technology of China (USTC)</a>, 
and received my Ph.D. degree in Pattern Recognition and Intelligent System from Multimedia Computing Group (MMC), National Laboratory of Pattern Recognition, 
Institute of Automation, Chinese Academy of Sciences, advised by <a href="http://nlpr-web.ia.ac.cn/mmc/homepage/csxu.html"  target="_blank">Prof. Changsheng Xu</a>, 
and co-supervised by <a href="https://faculty.bjtu.edu.cn/9129/"  target="_blank">Prof. Jitao Sang</a>. 
I was a research visitor in the China-Singapore Institute of Digital Media (CSIDM) and Department of Computing of The Hong Kong Polytechnic University, respectively. 



<p>
My research interests include embodied AI, computer vision, multi-modal computing, and generative models, etc.
Now I focus on developing learning mechanisms of perception and decision-making to achieve general-purpose robot autonomy.
</p>


<p>
<font size="" color="#C70039"> I am looking for highly-motivated students with solid mathematical background or proficient coding skills. 
If you are interested in working with me, please send me an email. Thanks! </italic> </font
</p>



</div>

<!*************************************************>


<!*************************** News*************************>
<div class="rightBox">
<p id="NEWS">
<font size="5"><b>NEWS</b></font> &nbsp; 
</p>




<ul>
<p style="text-align:justify"; text-justify:inter-ideograph;>



<li> 
<font size="3" color="#C70039"> [<I>July 27, 2023</I>] </italic> </font> Our paper 
"Human-Object-Object Interaction: Towards Human-Centric Complex Interaction Detection" is accepted by ACM MM-23 (CCF-A). 
</li>


<li> 
<font size="3" color="#C70039"> [<I>Dec 27, 2022</I>] </italic> </font> 邵焕同学获西南交通大学2022年度优秀硕士论文奖！ 
</li>



<li> 
<font size="3" color="#C70039"> [<I>June 30, 2022</I>] </italic> </font> Our paper 
"Domain-Specific Conditional Jigsaw Adaptation for Enhancing transferability and Discriminability" is accepted by ACM MM-22 (CCF-A). 
</li>



<li> 
<font size="3" color="#C70039"> [<I>Junly 4, 2021</I>] </italic> </font> Our paper 
"Hierarchical Multi-Task Learning for Diagram Question Answering with Multi-Modal Transformer" is accepted by ACM MM-21 (CCF-A, Oral). 
[<a href="https://news.swjtu.edu.cn/shownews-22598.shtml"  target="_blank">新闻报道</a>]
</li>


<li> 
<font size="3" color="#C70039"> [<I>June 24, 2021</I>] </italic> </font> Our paper 
"Contrastive learning in frequency domain for Non-I.I.D. image classification" is awarded as best paper at MMM-21.
[<a href="https://news.swjtu.edu.cn/shownews-22434.shtml"  target="_blank">新闻报道</a>]
</li>

<li> 
<font size="3" color="#C70039"> [<I>March 6, 2021</I>] </italic> </font> Our paper
"Meta-Learning Causal Feature Selection for Stable Prediction" is accepted by ICME-21 (Oral, acceptance rate =15%).
</li>

<li> 
<font size="3" color="#C70039"> [<I>June 1, 2020</I>] </italic> </font> Our paper
"Adversarial Multimodal Network for Movie Question Answering" is accepted by IEEE Trans. on Multimedia.
</li>


</ul>



</div>



<!****************************** TEACHING******************************>
<div class="rightBox">
<p id="TEACHING">
<font size="5"><b>TEACHING</b></font> &nbsp; 
</p>


<p>
<font size="3">
<b>Undergraduate Courses</b></font>
</p>


<ul>

<li>Digital Image Processing, B2790, SCAI004012, 2023--2024(1)
</li>


<li>Digital Image Processing, B2630, SCAI004012, 2022--2023(1)
</li>


<li>Digital Image Processing, B0600, 3143324, 2021--2022(1)
</li>

<li>Digital Image Processing, B0312, 0371053, 2020--2021(2)
</li>

<li>Digital Image Processing, B1250, 3143324, 2020--2021(1)
</li>

<li>Digital Image Processing, B0445, 0371053, 2019--2020(2)
</li>

<li>Digital Image Processing, B1932, 3143324, 2019--2020(1)
</li>

<li>Digital Image Processing, B0332, 0371053, 2018--2019(2)
</li>


</ul>


<p>
<font size="3">
<b>Graduate Courses</b></font>
</p>


<ul>

<li> Natural Language Processing. 2022--2023(2)
</li>


<li> Natural Language Processing. 2021--2022(2)
</li>

</ul>


</div>







<!**********************SELECTED PUBLICATIONS**************************>

<div class="rightBox">
<p id="PUBLICATIONS">
<font size="5"><b>SELECTED PUBLICATIONS</b></font>  &nbsp; <a href="#top">Go Top</a>
</p>

<!--
<p>
<font size="3">
<b>Journal Papers</b></font>
</p>
--> 


<ul>



<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Human-Object-Object Interaction: Towards Human-Centric Complex Interaction Detection<br>
Ming-Xuan Zhang, Xiao Wu, <strong>Zhaoquan Yuan</strong>, Qi He, Xiang Huang <br>
<I>ACM International Conference on Multimedia</I> (ACM MM-23), 2023. [CCF-A类]

</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Domain-Specific Conditional Jigsaw Adaptation for Enhancing Transferability and Discriminability<br>
Qi He, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Wu, and Jun-Yan He <br> 
<I>ACM International Conference on Multimedia</I> (ACM MM-22), 2022. [CCF-A类]

</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Learning Graph-based Residual Aggregation Network for Group Activity Recognition<br>
Wei Li, Tianzhao Yang, Xiao Wu, and <strong>Zhaoquan Yuan</strong><br> 
<I>International Joint Conference on Artificial Intelligence</I> (IJCAI-22), 2022. [Oral, CCF-A类]

</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Hierarchical Multi-Task Learning for Diagram Question Answering with Multi-Modal Transformer<br>
<strong>Zhaoquan Yuan</strong>, Xiao Peng, Xiao Wu<sup>*</sup>, and Changsheng Xu<br> 
<I>ACM International Conference on Multimedia</I> (ACM MM-21), 2021. [Oral, CCF-A类]
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Adversarial Multimodal Network for Movie Story Question Answering<br> 
<strong>Zhaoquan Yuan</strong>, Siyuan Sun, Lixin Duan<sup>*</sup>, Changsheng Li<sup>*</sup>, Xiao Wu, and Changsheng Xu<br> 
<I>IEEE Trans. on Multimedia</I> (TMM), 2021. [中科院JCR-1区]
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Meta-Learning Causal Feature Selection for Stable Prediction<br> 
<strong>Zhaoquan Yuan</strong>, Xiao Peng, Xiao Wu<sup>*</sup>, Bingkun Bao, and Changsheng Xu<br>
<I>IEEE International Conference on Multimedia & Expo</I> (ICME-21), 2021. [Oral, CCF-B类]
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Contrastive Learning in Frequency Domain for Non-I.I.D. Image Classification<br> 
Huan Shao, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Peng, and Xiao Wu<br> 
<I>International Conference on Multimedia Modeling</I> (MMM-21), 2021. [<strong>最佳论文奖</strong>]
</li>


  
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
DB-LSTM: Densely-Connected Bi-directional LSTM for Human Action Recognition<br> 
Jun-Yan He, Xiao Wu, Zhi-Qi Cheng, <strong>Zhaoquan Yuan</strong>, and Yu-Gang Jiang<br> 
 <I>Neurocomputing</I>, 2021. [中科院JCR-2区]
</li>
  

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Learning Feature Hierarchies: A Layer-Wise Tag-Embedded Approach<br> 
<strong>Zhaoquan Yuan</strong>, Changsheng Xu<sup>*</sup>, Jitao Sang, Shuicheng Yan, and M. Shamim Hossain<br> 
<I>IEEE Trans. on Multimedia </I>(TMM), 2015. [中科院JCR-1区]
</li>
  

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
A Unified Framework of Latent Feature Learning in Social Media<br> 
<strong>Zhaoquan Yuan</strong>, Jitao Sang, Changsheng Xu<sup>*</sup>, and Yan Liu<br> 
<I>IEEE Trans. on Multimedia</I> (TMM), 2014. [中科院JCR-1区]
</li>


  
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Latent Feature Learning in Social Media Network<br> 
<strong>Zhaoquan Yuan</strong>, Jitao Sang, Yan Liu, and Changsheng Xu<sup>*</sup><br> 
<I>ACM International Conference on Multimedia</I> (ACM MM-13), 2013. [Oral, CCF-A类]
</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Tag-aware Image Classification via Nested Deep Belief Nets<br> 
<strong>Zhaoquan Yuan</strong>, Jitao Sang, and Changsheng Xu<sup>*</sup><br> 
<I>IEEE International Conference on Multimedia & Expo</I> (ICME-13), 2013. [Oral, CCF-B类]
</li>

</ul>




</div>



<!**************** Grant and Funds****************>

<div class="rightBox">
<p id="FUNDS">
<font size="5"><b>GRANT AND FUNDS</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>

<ul>

<li>
Machine Learning and Reasoning in Video Question Answering, 2019.01 -- 2021.12, National Natural Science Foundation of China, 61802053
</li>

<li>
Machine Reasoning Research Towards Multimodal Question Answering, 2012.01 -- 2022.12, Sichuan Science and Technology Program, 2020YJ0037
</li>

<li>
Key Technologies of Video Question Answering System, China Postdoctoral Science Foundation, 2020M683353
</li>

<li>
Semantic Understanding toward Video Question Answering, 2019.01 -- 2020.12, Fundamental Research Funds for the Central Universities, 2682019CX62
</li>

</ul>



</div>



<!**************** Services ****************>

<div class="rightBox">
<p id="FUNDS">
<font size="5"><b>PROFESSIONAL ACTIVITIES</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>

<p>
<font size="3">
<b>Program Committee Member</b></font>
</p>

<ul>
<li>ACM International Conference on Multimedia, 2019 – present </li>
<li>Association for the Advancement of Artificial Intelligence, 2022 – present </li>
<li>Annual Meeting of the Association for Computational Linguistics, 2023 – present </li>
<li>International Conference on Empirical Methods in Natural Language Processing, 2021 – present </li>
<li>ACM International Conference on Multimedia Retrieval, 2019 – present </li>
<li>IEEE International Conference on Multimedia and Expo, 2019 – present </li>
<li>International Conference on Multimedia Modeling, 2019 – present </li>
<li>ACM International Conference on Multimedia in Asia, 2019 – present </li>


</ul>


<p>
<font size="3">
<b>Journal Reviewer</b></font>
</p>

<ul>


<li>IEEE Transactions on Multimedia </li>
<li>IEEE Transactions on Neural Networks and Learning Systems </li>
<li>IEEE Transactions on Cybernetics </li>
<li>Pattern Recognition </li>
<li>Multimedia Systems </li>
<li>Multimedia Tools and Applications </li>


</div>





<!**************** students****************>

<div class="rightBox">
<p id="STUDENTS">
<font size="5"><b>STUDENTS</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>


<!--
<p>
<font size="3">
<b>Collaborating Students</b></font>
</p>
-->


<p>
<font size="3">
<b>PhD Students</b></font>
</p>

<ul>

<li>Zhou Du (Co-superviser)
</li>

<li>Fangying Xiong (Co-superviser)
</li>

<li>Yuankang Pan (Co-superviser)
</li>



</ul>



<p>
<font size="3">
<b>Master Students</b></font>
</p>

<ul>

<li>Huancheng Xu
</li>

<li>Baili Zhou
</li>

<li>Jie Tang
</li>

<li>Zijia Liang
</li>

<li>Zining Wang
</li>

<li>Wen Xu
</li>

<li>Jiangbo Chai
</li>

<li>Zihao Luan
</li>

<li>Hongxiao Yuan
</li>

<li>Ting Pan
</li>



<li>Chengbin Zhao (Co-superviser)
</li>


<li>Bojie Ma (Co-superviser)
</li>

<li>Yuan Ma (Co-superviser)
</li>

<li>Zhun Zhong (Co-superviser)
</li>

<li>Zimeng Wang (Co-superviser)
</li>

<li>Shengkai Wan (Co-superviser)
</li>

<li>Xinhan Lian (Co-superviser)
</li>


<li>Xiao Peng (Graduated in 2022, 现就职于商汤科技)
</li>
<li>Huan Shao (Graduated in 2022, 现就职于蚂蚁金服)
</li>


</ul>


<p>
<font size="3">
<b>Undergraduate Students</b></font>
</p>

<ul>

<li>Yuxuan Bai
</li>


</ul>





</div>





<!*********************** RESOURCE**************************>
<div class="rightBox">
<p id="RESOURCE">
<font size="5"><b>RESOURCE</b></font>  &nbsp; <a href="#top">Go Top</a>
</p>


<ul>

  

  

<li><a href="https://openaccess.thecvf.com/menu"  target="_blank">Computer Vision Foundation</a>
</li>

<li><a href="https://dblp.uni-trier.de/db/conf/icra/index.html"  target="_blank">ICRA (DBLP)</a>
</li>


<!--
<li><a href="https://www.aclweb.org/portal/acl"  target="_blank">ACL Association for Computational Linguistics</a>
</li>

<li><a href="http://out-of-distribution-generalization.com/"  target="_blank">OOD Generalization</a>
</li>
-->

<li><a href="http://www.zhuanzhi.ai/topic/2001826911580295" target="_blank">专知知识分享平台</a>
</li>


</ul>


</div>




<!*************************招生信息************************>
<div class="rightBox">
<p id="recruit">
<font size="5"><b>招生信息</b></font>  &nbsp; <a href="#top">Go Top</a>
</p>

<p style="text-align:justify"; text-justify:inter-ideograph;>
袁召全，现任西南交通大学计算机与人工智能学院副教授，硕士生导师，任CCF、CAAI、IEEE、ACM会员。本科毕业于中国科学技术大学计算机科学与技术学院，博士毕业于中国科学院自动化研究所（模式识别国家重点实验室），师从徐常胜研究员。
曾先后在中国-新加坡数字媒体研究院、香港理工大学计算机科学系交流访问。曾获国际学术会议MMM 2021最佳论文奖。近年来在ACM MM、IJCAI、IEEE Trans. on Multimedia等国际学术会议及期刊发表论文10余篇。
任多届ACM MM、CVPR、ACL、AAAI、EMNLP、ICMR、ICME等国际会议程序委员会委员。 目前主持国家自然科学基金青年项目、四川省科技计划基础研究项目、中国博士后基金项目等多项。
主要研究方向包括具身智能、计算机视觉、生成式人工智能、视觉-语言多模态计算等。


<p>
<font size="" color="#C70039">
欢迎有上进心与科研热情、数学与编程基础扎实，对具身智能、计算机视觉、多模态计算、生成式AI等相关技术感兴趣的同学加入科研团队。有意向的同学请邮件联系：zqyuan0@gmail.com。
</strong> </italic> </font>
</p>

</div>
<!*************************************************>




<!*****************************updated date***********************************>
<div class="rightBox">

Last updated date: July 27, 2023.
<br>
</div>
<!*********************************Visit tracker**********************************>




</script>

</body>

</html>
