<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=gbk">
<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
<title>Zhaoquan Yuan's Homepage </title>
<style>
body {
font-family: "Times New Roman", "Helvetica Neue", Helvetica, Arial, sans-serif;
color: #444;
font-size: 62.5%;
background: #f4f4f4;
}

a:link,
a:visited {
color: #1279f8;
text-decoration: none;
}

a:hover {
text-decoration: underline;
}

.main {
display: flex;
}

.left {
font-size: 16px;
line-height: 1.3;
background: #fff;
border-radius: 6px;
-webkit-box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
position: fixed;
top: 8px;
left: 8px;
bottom: 8px;
float: left;
width: 285px;
min-width: 285px;
margin:0px;
}

.right {
margin: 0 0 0 10px;
flex-grow: 1;
font-size: 17px;
line-height: 1.8;
background: #fff;
border-radius: 6px;
margin-left: 295px;
padding-top:0px;
-webkit-box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
box-shadow: 0 1px 2px rgba(0, 0, 0, 0.07);
}

.rightBox {
padding: 5px 100px 20px;
border-top: 1px solid #eee;
position: relative;
}
.rightBox>p{
margin-top: -80px;
padding-top: 80px;
}

.rightBox table {
border-top: 1px solid #e2b0b5;
border-left: 1px solid #e2b0b5;   <!*********************>
}

.rightBox td,
.rightBox th {
border-right: 1px solid #e2b0b5;
border-bottom: 1px solid #e2b0b5;
}

.rightBox th {
padding: 10px;
}

.rightBox td {
font-size: 16px;
line-height: 1.8;
padding: 10px;
}

.right h4 {
font-family: "Roboto Condensed", sans-serif;
margin-bottom: 10px;
position: relative;
color: #000;
font-size: 18px;
line-height: 20px;
}

.text span {
border: orangered 1px solid;
color: #fff;
padding: 0px 8px;
margin-right: 8px;
border-radius: 10px;
color: orangered;
}

.box {
padding: 20px 30px;
border-top: 1px solid #eee;
position: relative;
}

h1 {
margin: 0 0 10px 0;
text-align: center;
font-size: 20px
}

h1 p {
text-align: center;
}

.headerImg {


display: block;
width: 200px;
height: 200px;
margin: 0 auto 5px auto;
border-radius: 10%;
}

h3 {
margin: 0 0 10px 0;
font-size: 18px;
font-weight: 500;
letter-spacing: .02em;
text-transform: uppercase;
color: #999;
}

.wrap {
position: fixed;
top: 8px; right: 8px; left: 303px;
border-bottom: 1px solid #f4f4f4;
background: #fff; z-index: 10;
}
.wrap:before {
display: block;
content: '';
position: fixed;
top: 0px; right: 8px; left: 303px; height: 8px;
background: #f4f4f4;

}

.wrap ul {
padding: 0 30px;
text-align: center;
}

.wrap li {
display: inline-block;
margin: 10px 10px 0 0;
font-size: 18px;
height: 20px;
line-height: 20px;
line-height: 1;
}

.wrap li:hover {}

.wrap li a {
display: inline-block;
color: #444;
}

.wrap li a {
text-decoration: none;
color: #444;
background: #fff;
padding: 6px;
}

.wrap li a:hover {
color: #fff;
background: #3399FF;  <!***************>
padding: 6px;
}
.backtop{
position: fixed;
right: 2rem;
bottom: 2rem;
z-index: 1000;
border: 1px solid red；
}
a>.btnbacktop{
font-size: 2rem;
margin: 1rem 0 0;
padding: 0;
width: 3.33rem;
height: 3.33rem;
line-height: 0;
color: #333;
background-color: #ffffff;
border: 1px solid #e3e8ee;
border-radius: 50%;
box-shadow: 0 0 5px rgba(0,0,0,.05);
}
#hqestop img{opacity:0.6;}

@media screen and (max-width: 1100px) {
.main {
flex-direction: column;

}
.main .wrap {
display: none;
}

.main .left {
width:100%;
left: 0px;
position: relative;
}

.main .right {
width: 100%;
margin: 10px 0 0 0;
box-sizing: border-box;
}
}
</style>
</head>

<!*************************个人信息************************>

<body>
<div class="main">
<div class="left">
<h1>
<p><img alt="" src="profilePhoto.JPG" style="WIDTH: 127px; HEIGHT: 180px" /></p>
<p><b>
Zhaoquan Yuan
</b>
</p>
</h1>


<div class="box">

<p> <i>Associate Professor, Ph.D.<br>
</i></p>

<p>
School of Computing and Artificial Intelligence, Southwest Jiaotong University</p>
<p>
Engineering Research Center of Sustainable Urban Intelligent Transportation, Ministry of Education, China
</p>

</div>


<div class="box">
<h3>contact</h3>
<p> ADRESS:
No. 999, Xi'an Road, Pidu District, Chengdu, China PR. 
</p>

<p> POSTCODE: 611756.
</p>

EMAIL:&nbsp; zqyuan0@gmail.com


<!----------->

</div>
<p></p>
</div>
</div>

<!*************************目录************************>

<div class="right">
<div class="wrap">
<ul>
<li><a href="index.html">HOMEPAGE</a></li> &nbsp; &nbsp; 
<li><a href="./#PUBLICATIONS">PUBLICATION</a></li> &nbsp; &nbsp; 
<li><a href="./#RESOURCE">RESOURCE</a></li> &nbsp; &nbsp; 
<li><a href="./#recruit">招生信息</a></li>


</ul>

</div>


<!*************************BRIEF BIOGRAPHY************************>
<div class="rightBox text">
<p id="BIOGRAPHY">
<br>
<br>
<br>
<font size="5"><b>BRIEF BIOGRAPHY</b></font>
</p>

<p style="text-align:justify"; text-justify:inter-ideograph;>

Zhaoquan Yuan is now an Associate Professor at the <a href="https://scai.swjtu.edu.cn/index.htm"  target="_blank">School of Computing and Artificial Intelligence</a>, 
and Vice Dean of the Institute of Advanced Technology and Equipment, Southwest Jiaotong University (SWJTU). 
I graduated with my bachelor's degree from the School of Computer Science and Technology, University of Science and Technology of China (USTC)</a>, 
and received my Ph.D. degree in Pattern Recognition and Intelligent System from Multimedia Computing Group (MMC), National Laboratory of Pattern Recognition, 
Institute of Automation, Chinese Academy of Sciences, advised by <a href="http://nlpr-web.ia.ac.cn/mmc/homepage/csxu.html"  target="_blank">Prof. Changsheng Xu</a>, 
and co-supervised by <a href="https://faculty.bjtu.edu.cn/9129/"  target="_blank">Prof. Jitao Sang</a>. 
I was a research visitor in the China-Singapore Institute of Digital Media (CSIDM) and Department of Computing of The Hong Kong Polytechnic University, respectively. 



<p>
My research interests encompass a variety of fields, including computer vision, compositional learning, and multi-modal semantic understanding, etc.

<!--
Currently, I am focusing on developing learning mechanisms for dynamics models to better understand the visual physical world.
注释：Now I focus on developing learning mechanisms of perception and decision-making to achieve general-purpose robot autonomy.
--> 

</p>


<p>
<font size="" color="#C70039"> I am looking for highly-motivated students with solid mathematical background or proficient coding skills. 
If you are interested in working with me, please send me an email. Thanks! </italic> </font
</p>



</div>

<br>

<!*************************************************>


<!*************************** News*************************>
<div class="rightBox">
<p id="NEWS">
<font size="5"><b>NEWS</b></font> &nbsp; 
</p>




<ul>
<p style="text-align:justify"; text-justify:inter-ideograph;>




<li> 
<font size="3" color="#C70039"> [<I>Dec 5, 2024</I>] </italic> </font> Our Paper 
"TMM-CLIP: Task-guided Multi-Modal Alignment for Rehearsal-Free Class Incremental Learning" is awarded as best paper at ACM MM Asia 2024.
</li>



<li> 
<font size="3" color="#C70039"> [<I>March 27, 2024</I>] </italic> </font> Paper 
"PostureHMR: Posture Transformation for 3D Human Mesh Recovery" is accepted by CVPR 2024 (CCF-A). 
</li>



<li> 
<font size="3" color="#C70039"> [<I>July 27, 2023</I>] </italic> </font> Paper 
"Human-Object-Object Interaction: Towards Human-Centric Complex Interaction Detection" is accepted by ACM MM 2023 (CCF-A). 
</li>


<li> 
<font size="3" color="#C70039"> [<I>Dec 27, 2022</I>] </italic> </font> 邵焕同学获西南交通大学2022年度优秀硕士论文奖！ 
</li>



<li> 
<font size="3" color="#C70039"> [<I>June 30, 2022</I>] </italic> </font> Paper 
"Domain-Specific Conditional Jigsaw Adaptation for Enhancing transferability and Discriminability" is accepted by ACM MM 2022 (CCF-A). 
</li>



<li> 
<font size="3" color="#C70039"> [<I>Junly 4, 2021</I>] </italic> </font> Paper 
"Hierarchical Multi-Task Learning for Diagram Question Answering with Multi-Modal Transformer" is accepted by ACM MM 2021 (CCF-A, Oral). 
</li>


<li> 
<font size="3" color="#C70039"> [<I>June 24, 2021</I>] </italic> </font> Paper 
"Contrastive learning in frequency domain for Non-I.I.D. image classification" is awarded as best paper at MMM 2021.
</li>



<li> 
<font size="3" color="#C70039"> [<I>June 1, 2020</I>] </italic> </font> Paper
"Adversarial Multimodal Network for Movie Question Answering" is accepted by IEEE Trans. on Multimedia.
</li>


</ul>



</div>

<br>


<!****************************** TEACHING******************************>
<div class="rightBox">
<p id="TEACHING">
<font size="5"><b>TEACHING</b></font> &nbsp; 
</p>


<p>
<font size="3">
<b>Undergraduate Courses</b></font>
</p>




<ul>

<li>Digital Image Processing, SCAI004012, 2024--2025(1)
</li>


<li>Natural Language Processing, SCAI008012, 2023--2024(2)
</li>


<li>Digital Image Processing, SCAI004012, 2023--2024(1)
</li>


<li>Digital Image Processing, SCAI004012, 2022--2023(1)
</li>


<li>Digital Image Processing, 3143324, 2021--2022(1)
</li>

<li>Digital Image Processing, 0371053, 2020--2021(2)
</li>

<li>Digital Image Processing, 3143324, 2020--2021(1)
</li>

<li>Digital Image Processing, 0371053, 2019--2020(2)
</li>

<li>Digital Image Processing, 3143324, 2019--2020(1)
</li>

<li>Digital Image Processing, 0371053, 2018--2019(2)
</li>


</ul>


<p>
<font size="3">
<b>Graduate Courses</b></font>
</p>


<ul>

<li> Natural Language Processing, 2023--2024(2)
</li>


<li> Natural Language Processing, 2022--2023(2)
</li>


<li> Natural Language Processing, 2021--2022(2)
</li>

</ul>


</div>



<br>



<!**********************SELECTED PUBLICATIONS**************************>

<div class="rightBox">
<p id="PUBLICATIONS">
<font size="5"><b>SELECTED PUBLICATIONS</b></font>  &nbsp; <a href="#top">Go Top</a>
</p>

<!--
<p>
<font size="3">
<b>Journal Papers</b></font>
</p>
--> 


<ul>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
TMM-CLIP: Task-guided Multi-Modal Alignment for Rehearsal-Free Class Incremental Learning.<br>
Yuankang Pan, <strong>Zhaoquan Yuan</strong>, Xiao Wu, Zechao Li,  Changsheng Xu.<br>
<I>Proceedings of ACM Multimedia Asia, pp. 1 - 7.  December 03–06, 2024, Auckland, New Zealand.  https://doi.org/10.1145/3696409.3700182. </I>
(MM Asia, <font size="3" color="#0000FF"> <strong>最佳论文奖</strong> </italic> </font>)
</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Person in Uniforms Re-Identification.<br>
Chongyang Xiang, Xiao Wu, Jun-Yan He,  <strong>Zhaoquan Yuan</strong>, Tingquan He.<br>
<I>ACM Transactions on Multimedia Computing Communications and Applications, 2024. 
Accepted on 23 October 2024
https://doi.org/10.1145/3703839.  </I>
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
MagicCartoon: 3D Pose and Shape Estimation for Bipedal Cartoon Characters.<br>
Yu-Pei Song, Yuantong Liu, Xiao Wu, Qi He,  <strong>Zhaoquan Yuan</strong>, Ao Luo.<br>
<I>Proceedings of the 32nd ACM International Conference on Multimedia, pp. 8219-8227. Oct 28–Nov 1, 2024, Melbourne, Australia. </I> (ACM MM, CCF-A类)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
PostureHMR: Posture Transformation for 3D Human Mesh Recovery.<br>
Yu-Pei Song, Xiao Wu, <strong>Zhaoquan Yuan</strong>, Jian-Jun Qiao, Qiang Peng.<br>
<I>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9732-9741. June 19-21, 2024. Seattle WA, USA.</I> (CVPR, CCF-A类)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Human-Object-Object Interaction: Towards Human-Centric Complex Interaction Detection.<br>
Ming-Xuan Zhang, Xiao Wu, <strong>Zhaoquan Yuan</strong>, Qi He, Xiang Huang.<br>
<I>Proceedings of the 31st ACM International Conference on Multimedia, pp. 2233-2242. 2023. Oct 29–Nov 3, 2023. Ottawa, Canada. </I> (ACM MM, CCF-A类)
</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Learning Surface-awareness Network for X-Ray Prohibited Item Detection.<br>
Ying Shen, Wei Li, <strong>Zhaoquan Yuan</strong>, Xiao Wu.<br>
<I>Proceedings of the 5th ACM International Conference on Multimedia in Asia, pp. 1-5. 2023. Dec 6-8, 2023. Tainan Taiwan. </I>
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Domain-Specific Conditional Jigsaw Adaptation for Enhancing Transferability and Discriminability.<br>
Qi He, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Wu, and Jun-Yan He.<br> 
<I>Proceedings of the 30th ACM International Conference on Multimedia, pp. 6327-6336. 2022. Oct 10-14, 2022. Lisbon Portugal. https://doi.org/10.1145/3503161.3547890. </I> (ACM MM, CCF-A类)

</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Learning Graph-based Residual Aggregation Network for Group Activity Recognition.<br>
Wei Li, Tianzhao Yang, Xiao Wu, and <strong>Zhaoquan Yuan</strong>.<br> 
<I>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, pp. 1102-1108. 2022. July 23-29, 2022.
Messe Wien, Vienna, Austria. </I> (IJCAI, CCF-A类)

</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Hierarchical Multi-Task Learning for Diagram Question Answering with Multi-Modal Transformer.<br>
<strong>Zhaoquan Yuan</strong>, Xiao Peng, Xiao Wu<sup>*</sup>, and Changsheng Xu.<br> 
<I>Proceedings of the 29th ACM International Conference on Multimedia, pp. 1313-1321, 2021. Oct 20-24, 2021. Chengdu, China. </I> (ACM MM, CCF-A类)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Adversarial Multimodal Network for Movie Story Question Answering.<br> 
<strong>Zhaoquan Yuan</strong>, Siyuan Sun, Lixin Duan<sup>*</sup>, Changsheng Li<sup>*</sup>, Xiao Wu, and Changsheng Xu.<br> 
<I>IEEE Transactions on Multimedia, vol. 23, pp. 1744-1756, 2021.</I> (TMM, 中科院JCR-1区)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Meta-Learning Causal Feature Selection for Stable Prediction.<br> 
<strong>Zhaoquan Yuan</strong>, Xiao Peng, Xiao Wu<sup>*</sup>, Bingkun Bao, and Changsheng Xu.<br>
<I>2021 IEEE International Conference on Multimedia and Expo (ICME), pp. 1-6. IEEE, 2021. July 5-9, 2021. Shenzhen, China. </I> (ICME, CCF-B类)
</li>


<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Contrastive Learning in Frequency Domain for Non-I.I.D. Image Classification.<br> 
Huan Shao, <strong>Zhaoquan Yuan<sup>*</sup></strong>, Xiao Peng, and Xiao Wu.<br> 
<I>Proceedings of the 27th International Conference on Multimedia Modeling, pp. 111-122, 2021. June 22–24, 2021. Prague, Czech Republic. </I> 
(MMM, <font size="3" color="#0000FF"> <strong>最佳论文奖</strong> </italic> </font>)
</li>


  
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
DB-LSTM: Densely-Connected Bi-directional LSTM for Human Action Recognition.<br> 
Jun-Yan He, Xiao Wu, Zhi-Qi Cheng, <strong>Zhaoquan Yuan</strong>, and Yu-Gang Jiang.<br> 
 <I>Neurocomputing, 444, pp.319-331.</I> (中科院JCR-2区)
</li>
  

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Learning Feature Hierarchies: A Layer-Wise Tag-Embedded Approach.<br> 
<strong>Zhaoquan Yuan</strong>, Changsheng Xu<sup>*</sup>, Jitao Sang, Shuicheng Yan, and M. Shamim Hossain.<br> 
<I>IEEE Transactions on Multimedia, vol. 17, no. 6, pp. 816-827, 2015.</I> (TMM, 中科院JCR-1区)
</li>
  

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
A Unified Framework of Latent Feature Learning in Social Media.<br> 
<strong>Zhaoquan Yuan</strong>, Jitao Sang, Changsheng Xu<sup>*</sup>, and Yan Liu.<br> 
<I>IEEE Transactions on Multimedia, vol. 16, no. 6, pp. 1624-1635, 2014.</I> (TMM, 中科院JCR-1区)
</li>


  
<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Latent Feature Learning in Social Media Network.<br> 
<strong>Zhaoquan Yuan</strong>, Jitao Sang, Yan Liu, and Changsheng Xu<sup>*</sup>.<br> 
<I>Proceedings of the 21st ACM international conference on Multimedia, pp. 253-262, 2013. Oct 21-25, 2013. Barcelona, Spain. </I> (ACM MM, CCF-A类)
</li>

<li>
<p style="text-align:justify"; text-justify:inter-ideograph;>
Tag-aware Image Classification via Nested Deep Belief Nets.<br> 
<strong>Zhaoquan Yuan</strong>, Jitao Sang, and Changsheng Xu<sup>*</sup>.<br> 
<I>2013 IEEE international conference on Multimedia and Expo, pp. 1-6. IEEE, 2013. July 15-19, 2013. San Jose, CA, USA. </I> (ICME, CCF-B类)
</li>

</ul>




</div>

<br>


<!**************** Rewards****************>

<div class="rightBox">
<p id="REWARD">
<font size="5"><b>REWARDS</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>

<ul>

<li>
国际学术会议 Multimedia Modeling 2021最佳论文奖
</li>

<li>
国际学术会议 ACM Multimedia Asia 2024最佳论文奖
</li>


<li>
2024年中国发明协会发明创业奖创新奖（二等，第二完成人）
</li>


</ul>



</div>

<br>


<!**************** Grant and Funds****************>

<div class="rightBox">
<p id="FUNDS">
<font size="5"><b>GRANT AND FUNDS</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>

<ul>

<li>
Intelligent Parameter Learning and Image Reconstruction in Adaptive Optical Systems, 2024.12 -- 2026.11, the Fund of National Laboratory on Adaptive Optics, China, FNLAO-24-ZD-O02
</li>


<li>
Causal Mechanism-based Multimodal Continual Learning, 2024.01 -- 2025.12, Natural Science Foundation of Sichuan Province, 2024NSFSC0508
</li>


<li>
Machine Learning and Reasoning in Video Question Answering, 2019.01 -- 2021.12, National Natural Science Foundation of China, 61802053
</li>

<li>
Machine Reasoning Research Towards Multimodal Question Answering, 2020.01 -- 2022.12, Sichuan Science and Technology Program, 2020YJ0037
</li>

<li>
Key Technologies of Video Question Answering System, China Postdoctoral Science Foundation, 2020M683353
</li>

<li>
Semantic Understanding toward Video Question Answering, 2019.01 -- 2020.12, Fundamental Research Funds for the Central Universities, 2682019CX62
</li>

</ul>



</div>


<br>

<!**************** Services ****************>

<div class="rightBox">
<p id="FUNDS">
<font size="5"><b>PROFESSIONAL ACTIVITIES</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>

<p>
<font size="3">
<b>Program Committee Member</b></font>
</p>




<ul>

<!--
<li>IEEE Conference on Computer Vision and Pattern Recognition, 2023 – present </li>
<li>International Conference on Computer Vision, 2024 – present </li>
<li>Annual Conference on Neural Information Processing Systems, 2024 – present </li>
-->

<li>ACM International Conference on Multimedia, 2019 – present </li>
<li>Association for the Advancement of Artificial Intelligence, 2022 – present </li>
<li>International Joint Conference on Artificial Intelligence, 2023 – present </li>
<li>Annual Meeting of the Association for Computational Linguistics, 2023 – present </li>
<li>International Conference on Empirical Methods in Natural Language Processing, 2021 – present </li>
<li>ACM International Conference on Multimedia Retrieval, 2019 – present </li>
<li>IEEE International Conference on Multimedia and Expo, 2019 – present </li>
<li>International Conference on Multimedia Modeling, 2019 – present </li>
<li>ACM International Conference on Multimedia in Asia, 2019 – present </li>




</ul>


<p>
<font size="3">
<b>Journal Reviewer</b></font>
</p>

<ul>

<!--
<li>IEEE Transactions on Image Processing </li>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence  </li>
-->

<li>IEEE Transactions on Multimedia </li>
<li>IEEE Transactions on Neural Networks and Learning Systems </li>
<li>IEEE Transactions on Cybernetics </li>
<li>ACM Transactions on Multimedia Computing Communications and Applications</li>
<li>Pattern Recognition </li>
<li>Multimedia Systems </li>
<li>Multimedia Tools and Applications </li>


</div>

<br>




<!**************** students****************>

<div class="rightBox">
<p id="STUDENTS">
<font size="5"><b>STUDENTS</b> </font> &nbsp; <a href="#top">Go Top</a>
</p>


<!--
<p>
<font size="3">
<b>Collaborating Students</b></font>
</p>
-->


<p>
<font size="3">
<b>PhD Students</b></font>
</p>

<ul>


<li>Jing Zhou (Co-superviser)
</li>


<li>Yuankang Pan (Co-superviser)
</li>


<li>Fangying Xiong (Co-superviser)
</li>



<li>Zhou Du (Co-superviser)
</li>





</ul>



<p>
<font size="3">
<b>Master Students</b></font>
</p>

<ul>

<li>Yuting Liu, Yuan Lin, Guoshuai Liang, Liaoliao Ren (Co-superviser), Kunlin Liang (Co-superviser)
</li>



<li>Yuke Li, Yuting Tang, Maorui Zhang, Cong Zheng, Xuehui Chen, Yang Liu (Co-superviser), Tao Liu (Co-superviser), Jicheng Liu (Co-superviser)
</li>





<li>Zihao Luan, Jiangbo Chai, Hongxiao Yuan, Ting Pan, Fanpeng Li, Zimeng Wang (Co-superviser), Shengkai Wan (Co-superviser), Xinhan Lian (Co-superviser)
</li>




<li>Zining Wang, Wen Xu, Jie Tang, Zijia Liang, Bojie Ma (Co-superviser), Yuan Ma (Co-superviser), Zhun Zhong (Co-superviser)
</li>




</ul>



<p>
<font size="3">
<b> Graduated Students</b></font>
</p>

<ul>

<li>Chengbin Zhao, Huancheng Xu, Baili Zhou, Huan Shao (优秀硕士论文奖), Xiao Peng
</li>

</ul>


<br>


</div>





<!*********************** RESOURCE**************************>
<div class="rightBox">
<p id="RESOURCE">
<font size="5"><b>RESOURCE</b></font>  &nbsp; <a href="#top">Go Top</a>
</p>


<ul>

  

  

<li><a href="https://openaccess.thecvf.com/menu"  target="_blank">Computer Vision Foundation</a>
</li>

<li><a href="https://proceedings.neurips.cc/"  target="_blank">NeurIPS Proceedings</a>
</li>

<li><a href="https://proceedings.mlr.press/"  target="_blank">PMLR</a>
</li>


<!--
<li><a href="https://www.aclweb.org/portal/acl"  target="_blank">ACL Association for Computational Linguistics</a>
</li>

<li><a href="http://out-of-distribution-generalization.com/"  target="_blank">OOD Generalization</a>
</li>
-->

<li><a href="http://www.zhuanzhi.ai/topic/2001826911580295" target="_blank">专知知识分享平台</a>
</li>

<br>


</ul>


</div>




<!*************************招生信息************************>
<div class="rightBox">
<p id="recruit">
<font size="5"><b>招生信息</b></font>  &nbsp; <a href="#top">Go Top</a>
</p>



<p style="text-align:justify"; text-justify:inter-ideograph;>

袁召全，现任西南交通大学计算机与人工智能学院副教授，硕士生导师。本科毕业于中国科学技术大学计算机科学与技术学院，博士毕业于中国科学院大学（中国科学院自动化研究所）。
曾先后在中国-新加坡数字媒体研究院、香港理工大学计算机科学系交流访问。
曾获国际学术会议ACM MM Asia 2024最佳论文奖、MMM 2021最佳论文奖、2024年度中国发明协会发明创业奖创新奖、2024年度广西应急管理协会安全科技进步奖。
近年来在CVPR、ACM MM、IJCAI、IEEE TMM等国际学术会议及期刊发表论文20余篇。
任多届CVPR、ACM MM、ACL、AAAI、IJCAI、EMNLP、ICMR、ICME等国际会议程序委员会委员，及多个IEEE Trans、ACM Trans期刊审稿人。
所指导的研究生曾获西南交通大学优秀硕士论文奖。
目前主持国家自然科学基金青年项目、四川省自然科学基金项目、四川省科技计划基础研究项目、中国博士后基金项目等多项。
主要研究方向包括计算机视觉、组合学习、三维重构与生成、多模态语义分析等。



<br>


<p>
<font size="" color="#C70039">
欢迎具备以下条件的同学加入科研团队：<br>
（1）良好的自我驱动力，对学术探索/工程技术有强烈的兴趣与热情；<br>
（2）数学与编程基础扎实，对计算机视觉、深度学习、3D视觉、多模态等AI前沿技术感兴趣；<br>
（3）责任心强，有团队合作精神，诚信可靠。<br>
有意向的同学请邮件联系：zqyuan0@gmail.com
</strong> </italic> </font>
</p>

<br>

</div>
<!*************************************************>




<!*****************************updated date***********************************>
<div class="rightBox">

Last updated date: Dec 6, 2024.
<br>
</div>
<!*********************************Visit tracker**********************************>




</script>

</body>

</html>
